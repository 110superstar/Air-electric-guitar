{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_list2 = [[8, 7, 6, 5], [12, 11, 10, 9], [16, 15, 14, 13], [20, 19, 18, 17]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_gesture(angle_list):\n",
    "    threshold1 = 140\n",
    "    threshold2 = 140\n",
    "    if angle_list[0][1] > threshold1:\n",
    "        if angle_list[1][1] > threshold1:\n",
    "            if angle_list[2][1] > threshold1:\n",
    "                if angle_list[3][1] > threshold1:\n",
    "                    return 'four'\n",
    "                else:\n",
    "                    return 'three'\n",
    "            else:\n",
    "                return 'two'\n",
    "        else:\n",
    "            if angle_list[2][1] > threshold1:\n",
    "                return 'one'\n",
    "            else:\n",
    "                if angle_list[3][1] > threshold1:\n",
    "                    return 'rock'\n",
    "                else:\n",
    "                    return 'one'\n",
    "    else:\n",
    "        return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def draw_and_get_finger_angles2(image, results, joint_list2):\n",
    "    \n",
    "    pos = 20\n",
    "    RLmultiply = 0\n",
    "    distance = None\n",
    "    gesture = None\n",
    "    # Loop through hands\n",
    "    for RL, hand in enumerate(results.multi_hand_landmarks):\n",
    "        angle_list = []\n",
    "        try:\n",
    "            if results.multi_handedness[RL].classification[0].label == 'Right':\n",
    "                RLmultiply = 1\n",
    "            else:\n",
    "                RLmultiply = 0\n",
    "        except:\n",
    "            pass\n",
    "        #Loop through joint sets \n",
    "        for num, joint in enumerate(joint_list2):\n",
    "            a = np.array([hand.landmark[joint[0]].x, hand.landmark[joint[0]].y]) # First coord\n",
    "            b = np.array([hand.landmark[joint[1]].x, hand.landmark[joint[1]].y]) # Second coord\n",
    "            c = np.array([hand.landmark[joint[2]].x, hand.landmark[joint[2]].y]) # Third coord\n",
    "            d = np.array([hand.landmark[joint[3]].x, hand.landmark[joint[3]].y]) # Fuorth coord\n",
    "            e = np.array([hand.landmark[0].x, hand.landmark[0].y]) # Fifth coord\n",
    "            \n",
    "            radians1 = np.arctan2(b[1] - c[1], b[0]-c[0]) - np.arctan2(d[1]-c[1], d[0]-c[0])\n",
    "            radians2 = np.arctan2(c[1] - d[1], c[0]-d[0]) - np.arctan2(e[1]-d[1], e[0]-d[0])\n",
    "            angle1 = np.abs(radians1*180.0/np.pi)\n",
    "            angle2 = np.abs(radians2*180.0/np.pi)\n",
    "            \n",
    "            if angle1 > 180.0:\n",
    "                angle1 = 360-angle1\n",
    "            if angle2 > 180.0:\n",
    "                angle2 = 360-angle2\n",
    "            \n",
    "            angle_list.append((angle1, angle2))\n",
    "                \n",
    "            cv2.putText(image, str(round(angle1, 2)), (pos + num * 80 + RLmultiply * 320, 20),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(angle2, 2)), (pos + num * 80 + RLmultiply * 320, 40),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        if RLmultiply == 1:\n",
    "            distance = math.sqrt((hand.landmark[4].x - hand.landmark[12].x)**2 + (hand.landmark[4].y - hand.landmark[12].y)**2)\n",
    "            cv2.putText(image, str(round(distance, 2)), (int(hand.landmark[0].x * 640), int(hand.landmark[0].y * 480) + 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        if RLmultiply == 0:\n",
    "            gesture = decide_gesture(angle_list)\n",
    "            cv2.putText(image, gesture, (int(hand.landmark[0].x * 640), int(hand.landmark[0].y * 480) + 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return image, distance, gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line(image,left_WRIST_y_coord):\n",
    "    start_point = (0, left_WRIST_y_coord)\n",
    "    end_point = (640, left_WRIST_y_coord)\n",
    "    color = (0, 255, 0)\n",
    "    thickness = 2\n",
    "    image = cv2.line(image, start_point, end_point, color, thickness)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_mode_0 = {\n",
    "    'one':\"C\",\n",
    "    'two':\"A\",\n",
    "    'three':\"D\",\n",
    "    'four':\"G\"\n",
    "}\n",
    "chord_mode_1 = {\n",
    "    'one':\"1\",\n",
    "    'two':\"2\",\n",
    "    'three':\"3\",\n",
    "    'four':\"4\"\n",
    "}\n",
    "chord_modes = [num2chord_1, num2chord_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_chord_mode(chord_mode):\n",
    "    num_of_mode = len(chord_modes)-1\n",
    "    if chord_mode+1 <= num_of_mode:\n",
    "        return chord_mode + 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_WRIST_coord(image, results):\n",
    "    left_WRIST_y_coord = None\n",
    "    right_WRIST_y_coord = None\n",
    "    for RL, hand in enumerate(results.multi_hand_landmarks):\n",
    "        if results.multi_handedness[RL].classification[0].label == 'Left':\n",
    "            \n",
    "            left_WRIST_y_coord = int(hand.landmark[mp_hands.HandLandmark.WRIST].y * 480)\n",
    "            image = draw_line(image,left_WRIST_y_coord)\n",
    "            \n",
    "        else:\n",
    "            right_WRIST_y_coord = int(hand.landmark[mp_hands.HandLandmark.WRIST].y * 480)\n",
    "        \n",
    "    return image, left_WRIST_y_coord, right_WRIST_y_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change chord mode!\n",
      "change chord mode!\n",
      "Thread G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        close music/G_chord.mp3\n",
      "    指定的裝置未開啟，或無法由 MCI 所辨認。\n",
      "Failed to close the file: music/G_chord.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change chord mode!\n",
      "change chord mode!\n",
      "Thread C\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "counter = 0 # 計算偵數，讓模式間隔 N 偵以上才能切換\n",
    "chord_mode = 0\n",
    "N = 50\n",
    "threshold = 0.2 \n",
    "Status = True\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detections\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Rendering results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n",
    "                                         )\n",
    "                image, left_WRIST_y_coord, right_WRIST_y_coord = find_WRIST_coord(image, results)\n",
    "                #print(\"left_WRIST_y_coord: \",left_WRIST_y_coord,\"right_WRIST_y_coord: \",right_WRIST_y_coord,)\n",
    "        \n",
    "            # Draw angles to image from joint list\n",
    "            image, distance, gesture = draw_and_get_finger_angles2(image, results, joint_list2)\n",
    "            \n",
    "        # Save our image    \n",
    "        #cv2.imwrite(os.path.join('Output Images', '{}.jpg'.format(uuid.uuid1())), image)\n",
    "        \n",
    "        try:\n",
    "            if right_WRIST_y_coord < left_WRIST_y_coord:\n",
    "                Status = True          \n",
    "\n",
    "            if gesture and right_WRIST_y_coord > left_WRIST_y_coord and Status: \n",
    "                play_chord(chord_modes[chord_mode][gesture])\n",
    "                counter = 0\n",
    "                Status = False\n",
    "\n",
    "#             if distance > threshold:\n",
    "#                 Status = True\n",
    "#             if gesture and distance < threshold and counter > N and Status: # counter>20 讓音樂間隔 N 偵以上播放\n",
    "#                 play_chord(num2chord[gesture])\n",
    "#                 counter = 0\n",
    "#                 Status = False\n",
    "        except:\n",
    "            try:\n",
    "                if gesture == 'rock' and counter > N : # counter>20 讓模式間隔 N 偵以上才能切換\n",
    "                    chord_mode = change_chord_mode(chord_mode)\n",
    "                    print(\"change chord mode!\")\n",
    "                    counter = 0\n",
    "                elif gesture == 'rock':\n",
    "                    text = 'CHMOD'\n",
    "                    cv2.putText(image, text, (150, 200), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                      3, (0, 255, 255), 9, cv2.LINE_AA)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "        counter = counter +1 \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rock'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeeee\n"
     ]
    }
   ],
   "source": [
    "if gesture == 'rock':\n",
    "    print(\"yeeee\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gesture == 'rock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chord_mode = change_chord_mode(chord_mode)\n",
    "chord_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread C\n",
      "Thread A\n",
      "Thread D\n",
      "Thread G\n",
      "Thread 1\n",
      "Thread 2\n",
      "Thread 3\n",
      "Thread 4\n"
     ]
    }
   ],
   "source": [
    "from playsound import playsound\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def init_play_chord(chord):\n",
    "    print(\"Thread\", chord)\n",
    "    playsound('music/{}_chord.mp3'.format(chord)) # 讓初次載入時發出聲音\n",
    "    \n",
    "def play_chord(chord):\n",
    "    threads[chords[chord]] = threading.Thread(target = init_play_chord, args = (chord,))\n",
    "    threads[chords[chord]].start()\n",
    "\n",
    "chords = {\n",
    "    \"C\": 0,\n",
    "    \"A\": 1,\n",
    "    \"D\": 2,\n",
    "    \"G\": 3,\n",
    "    \"1\": 0,\n",
    "    \"2\": 1,\n",
    "    \"3\": 2,\n",
    "    \"4\": 3\n",
    "}\n",
    "\n",
    "# 建立 4 個子執行緒\n",
    "threads = []\n",
    "for i, chord_name in enumerate(chords):\n",
    "    threads.append(threading.Thread(target = init_play_chord, args = (chord_name,)))\n",
    "    threads[i].start()\n",
    "    time.sleep(2)\n",
    "    \n",
    "for i in range(4):\n",
    "    threads[i].join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "counter = 0 # 計算偵數，讓模式間隔 N 偵以上才能切換\n",
    "chord_mode = 0\n",
    "N = 50\n",
    "threshold = 0.2 \n",
    "Status = True\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detections\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Rendering results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n",
    "                                         )\n",
    "                image, left_WRIST_y_coord, right_WRIST_y_coord = find_WRIST_coord(image, results)\n",
    "                #print(\"left_WRIST_y_coord: \",left_WRIST_y_coord,\"right_WRIST_y_coord: \",right_WRIST_y_coord,)\n",
    "        \n",
    "            # Draw angles to image from joint list\n",
    "            image, distance, gesture = draw_and_get_finger_angles2(image, results, joint_list2)\n",
    "            \n",
    "        # Save our image    \n",
    "        #cv2.imwrite(os.path.join('Output Images', '{}.jpg'.format(uuid.uuid1())), image)\n",
    "        \n",
    "        try:\n",
    "            if right_WRIST_y_coord < left_WRIST_y_coord:\n",
    "                Status = True          \n",
    "\n",
    "            if gesture and right_WRIST_y_coord > left_WRIST_y_coord and Status: \n",
    "                play_chord(chord_modes[chord_mode][gesture])\n",
    "                counter = 0\n",
    "                Status = False\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                if gesture == 'rock' and counter > N : # counter>20 讓模式間隔 N 偵以上才能切換\n",
    "                    chord_mode = change_chord_mode(chord_mode)\n",
    "                    print(\"change chord mode!\")\n",
    "                    counter = 0\n",
    "                elif gesture == 'rock':\n",
    "                    text = 'CHMOD'\n",
    "                    cv2.putText(image, text, (0, 100), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                      3, (0, 255, 255), 9, cv2.LINE_AA)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        cv2.putText(image, text, (470, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "        counter = counter +1 \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
